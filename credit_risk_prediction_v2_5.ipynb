{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMilAwiOxzqrW6fWT4aAoqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Attabeezy/sequential-crm-for-dce/blob/main/credit_risk_prediction_v2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqx1HL-XCEuq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Credit Risk Prediction\n",
        "\n",
        "This script implements an optimized approach for credit risk prediction\n",
        "Uses Artificial Neural Network (ANN) with feature engineering and the\n",
        "downsample_upsample data balancing strategy.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, roc_auc_score, classification_report,\n",
        "                            confusion_matrix, roc_curve, auc, precision_recall_curve)\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.makedirs('./results', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STEP 1: DATA LOADING AND PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def create_binary_target(df, positive_class):\n",
        "    \"\"\"Creates binary target variable from loan_status.\"\"\"\n",
        "    df_clean = df.copy()\n",
        "    df_clean['loan_status_binary'] = df_clean['loan_status'].apply(\n",
        "        lambda x: 1 if x == positive_class else 0\n",
        "    )\n",
        "    unique_statuses = df_clean['loan_status'].unique()\n",
        "    encoding_info = {status: (1 if status == positive_class else 0)\n",
        "                    for status in unique_statuses}\n",
        "    return df_clean, encoding_info\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "dataset_path = kagglehub.dataset_download('jeandedieunyandwi/lending-club-dataset')\n",
        "file_path = f\"{dataset_path}/lending_club_loan_two.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(f\"✓ Dataset shape: {df.shape}\")\n",
        "\n",
        "# Create binary target\n",
        "df_clean, encoding_info = create_binary_target(df, positive_class='Charged Off')\n",
        "\n",
        "# Sample and preprocess\n",
        "SAMPLE_SIZE = 60000\n",
        "X_clean = df_clean.drop(['loan_status', 'loan_status_binary'], axis=1)\n",
        "y_clean = df_clean['loan_status_binary']\n",
        "\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
        ")\n",
        "\n",
        "if len(X_train_full) > SAMPLE_SIZE:\n",
        "    train_indices = X_train_full.sample(n=SAMPLE_SIZE, random_state=42).index\n",
        "    df_sampled = df_clean.loc[train_indices].copy()\n",
        "else:\n",
        "    df_sampled = df_clean.loc[X_train_full.index].copy()\n",
        "\n",
        "X_sampled = df_sampled.drop(['loan_status', 'loan_status_binary'], axis=1)\n",
        "y_sampled = df_sampled['loan_status_binary']\n",
        "\n",
        "# Feature engineering\n",
        "FEATURE_COLUMNS = [\n",
        "    'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n",
        "    'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
        "    'annual_inc', 'application_type'\n",
        "]\n",
        "\n",
        "available_cols = [col for col in FEATURE_COLUMNS if col in X_sampled.columns]\n",
        "\n",
        "# Clean string columns\n",
        "if 'term' in X_sampled.columns and X_sampled['term'].dtype == 'object':\n",
        "    X_sampled['term'] = X_sampled['term'].str.replace(' months', '', regex=False).astype(float)\n",
        "\n",
        "if 'int_rate' in X_sampled.columns and X_sampled['int_rate'].dtype == 'object':\n",
        "    X_sampled['int_rate'] = X_sampled['int_rate'].str.replace('%', '', regex=False).astype(float)\n",
        "\n",
        "if 'emp_length' in X_sampled.columns and X_sampled['emp_length'].dtype == 'object':\n",
        "    X_sampled['emp_length'] = X_sampled['emp_length'].replace({\n",
        "        '< 1 year': '0', '1 year': '1', '2 years': '2', '3 years': '3', '4 years': '4',\n",
        "        '5 years': '5', '6 years': '6', '7 years': '7', '8 years': '8', '9 years': '9',\n",
        "        '10+ years': '10', 'n/a': np.nan\n",
        "    }).astype(float)\n",
        "\n",
        "# Select features and one-hot encode\n",
        "final_features = [col for col in available_cols if X_sampled[col].dtype in ['float64', 'int64']]\n",
        "categorical_features = ['grade', 'application_type']\n",
        "final_features.extend([c for c in categorical_features if c in X_sampled.columns])\n",
        "\n",
        "X_final = X_sampled[final_features].copy()\n",
        "y_final = y_sampled.copy()\n",
        "\n",
        "combined_df = pd.concat([X_final, y_final], axis=1)\n",
        "combined_df.dropna(inplace=True)\n",
        "\n",
        "X_final = combined_df.drop('loan_status_binary', axis=1)\n",
        "y_final = combined_df['loan_status_binary']\n",
        "\n",
        "X_encoded = pd.get_dummies(X_final, columns=[c for c in categorical_features if c in X_final.columns], drop_first=True)\n"
      ],
      "metadata": {
        "id": "211YI6bbC1ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: FEATURE ENGINEERING (BEST APPROACH)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nApplying feature engineering...\")\n",
        "X_engineered = X_encoded.copy()\n",
        "\n",
        "# Create ratio feature\n",
        "X_engineered['annual_inc_to_loan_amnt_ratio'] = X_engineered['annual_inc'] / (X_engineered['loan_amnt'] + 1e-6)\n",
        "\n",
        "# Select optimal features (based on correlation analysis)\n",
        "selected_features = ['loan_amnt', 'term', 'int_rate', 'emp_length', 'annual_inc',\n",
        "                    'annual_inc_to_loan_amnt_ratio']\n",
        "\n",
        "# Add one-hot encoded features\n",
        "ohe_cols = [col for col in X_engineered.columns if col.startswith('grade_') or col.startswith('application_type_')]\n",
        "selected_features.extend(ohe_cols)\n",
        "selected_features = [f for f in selected_features if f in X_engineered.columns]\n",
        "\n",
        "X = X_engineered[selected_features].copy()\n",
        "y = y_final.copy()\n",
        "\n",
        "print(f\"✓ Final data: {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "print(f\"  Features: {selected_features}\")\n"
      ],
      "metadata": {
        "id": "e1bGQPIwC5GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: DATA BALANCING (downsample_upsample)\n",
        "\n",
        "def prepare_data_with_downsample_upsample(X, y, random_state=None):\n",
        "    \"\"\"Applies downsample_upsample balancing strategy.\"\"\"\n",
        "    X_resampled, y_resampled = X.copy(), y.copy()\n",
        "\n",
        "    majority_class = y_resampled.value_counts().idxmax()\n",
        "    minority_class = y_resampled.value_counts().idxmin()\n",
        "\n",
        "    # Downsample majority\n",
        "    rus = RandomUnderSampler(\n",
        "        sampling_strategy={majority_class: y_resampled.value_counts()[minority_class]},\n",
        "        random_state=random_state\n",
        "    )\n",
        "    X_downsampled, y_downsampled = rus.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "    # Upsample minority\n",
        "    ros = RandomOverSampler(\n",
        "        sampling_strategy={minority_class: len(y_downsampled[y_downsampled == majority_class])},\n",
        "        random_state=random_state\n",
        "    )\n",
        "    X_resampled, y_resampled = ros.fit_resample(X_downsampled, y_downsampled)\n",
        "\n",
        "    # Shuffle\n",
        "    combined_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "    combined_df = combined_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    X_resampled = combined_df.drop(y_resampled.name, axis=1)\n",
        "    y_resampled = combined_df[y_resampled.name]\n",
        "\n",
        "    balance_info = {\n",
        "        'original_counts': y.value_counts().to_dict(),\n",
        "        'resampled_counts': y_resampled.value_counts().to_dict()\n",
        "    }\n",
        "\n",
        "    return X_resampled, y_resampled, balance_info\n",
        "\n",
        "print(\"\\nApplying downsample_upsample balancing...\")\n",
        "X_balanced, y_balanced, balance_info = prepare_data_with_downsample_upsample(X, y, random_state=42)\n",
        "print(f\"✓ Original counts: {balance_info['original_counts']}\")\n",
        "print(f\"✓ Balanced counts: {balance_info['resampled_counts']}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✓ Train set: {len(y_train):,} samples\")\n",
        "print(f\"✓ Test set: {len(y_test):,} samples\\n\")\n"
      ],
      "metadata": {
        "id": "vZt0fPEVC7-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: BUILD AND TRAIN BEST ANN MODEL\n",
        "\n",
        "def build_best_ann(input_shape):\n",
        "    \"\"\"Best performing ANN architecture: 2 hidden layers with tanh activation.\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(14, activation='tanh', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(7, activation='tanh'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_keras_with_cv(build_model_func, X, y, cv_folds=5,\n",
        "                                     epochs=50, batch_size=32, random_state=None,\n",
        "                                     model_name=\"\", verbose=False):\n",
        "    \"\"\"Train and evaluate Keras model with Stratified K-Fold CV.\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
        "    fold_results = []\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n--- {model_name} Cross-Validation ---\")\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "        start_time = time.time()\n",
        "\n",
        "        if isinstance(X, (pd.DataFrame, pd.Series)):\n",
        "            X_train_cv, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        else:\n",
        "            X_train_cv, X_val = X[train_index], X[val_index]\n",
        "\n",
        "        if isinstance(y, (pd.DataFrame, pd.Series)):\n",
        "            y_train_cv, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "        else:\n",
        "            y_train_cv, y_val = y[train_index], y[val_index]\n",
        "\n",
        "        model = build_model_func()\n",
        "        model.fit(X_train_cv, y_train_cv, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        y_pred_proba = model.predict(X_val, verbose=0).flatten()\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        precision = precision_score(y_val, y_pred, average='binary', zero_division=0)\n",
        "        recall = recall_score(y_val, y_pred, average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_val, y_pred, average='binary', zero_division=0)\n",
        "        macro_f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "        recall_class_1 = recall_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
        "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "        fold_time = time.time() - start_time\n",
        "\n",
        "        fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'macro_f1': macro_f1,\n",
        "            'recall_class_1': recall_class_1,\n",
        "            'roc_auc': roc_auc,\n",
        "            'time': fold_time,\n",
        "            'y_true': y_val,\n",
        "            'y_pred': y_pred,\n",
        "            'y_pred_proba': y_pred_proba\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  Fold {fold+1} completed in {fold_time:.2f} seconds.\")\n",
        "            print(f\"    Accuracy: {accuracy:.4f}, Macro-F1: {macro_f1:.4f}, \"\n",
        "                  f\"Recall (Class 1): {recall_class_1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "    mean_metrics = {}\n",
        "    std_metrics = {}\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1', 'macro_f1', 'recall_class_1', 'roc_auc', 'time']:\n",
        "        mean_metrics[f'{metric}_mean'] = np.mean([res[metric] for res in fold_results])\n",
        "        std_metrics[f'{metric}_std'] = np.std([res[metric] for res in fold_results])\n",
        "\n",
        "    cv_summary = {**mean_metrics, **std_metrics}\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n--- Average Results for {model_name} ---\")\n",
        "        print(f\"  Accuracy: {cv_summary['accuracy_mean']:.4f} ± {cv_summary['accuracy_std']:.4f}\")\n",
        "        print(f\"  Macro-F1: {cv_summary['macro_f1_mean']:.4f} ± {cv_summary['macro_f1_std']:.4f}\")\n",
        "        print(f\"  Recall (Class 1): {cv_summary['recall_class_1_mean']:.4f} ± {cv_summary['recall_class_1_std']:.4f}\")\n",
        "        print(f\"  ROC-AUC: {cv_summary['roc_auc_mean']:.4f} ± {cv_summary['roc_auc_std']:.4f}\")\n",
        "        print(\"-\" * (len(model_name) + 28))\n",
        "\n",
        "    return cv_summary, fold_results\n",
        "\n",
        "print(\"Training Best ANN Model with 5-fold Cross-Validation...\")\n",
        "ann_cv_results, ann_fold_details = train_and_evaluate_keras_with_cv(\n",
        "    lambda: build_best_ann(X_train_scaled.shape[1]),\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    cv_folds=5,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    random_state=42,\n",
        "    model_name='Best ANN (2HL-Tanh + Selected Features)',\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Train final model on full training set\n",
        "print(\"\\nTraining final model on full training set...\")\n",
        "ann_final = build_best_ann(X_train_scaled.shape[1])\n",
        "ann_final.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "ann_test_proba = ann_final.predict(X_test_scaled, verbose=0).flatten()\n",
        "ann_test_pred = (ann_test_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"✓ Model training complete\\n\")\n"
      ],
      "metadata": {
        "id": "LGJsR44CDC0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: EVALUATION AND RESULTS\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Accuracy:          {ann_cv_results['accuracy_mean']:.4f} ± {ann_cv_results['accuracy_std']:.4f}\")\n",
        "print(f\"Macro-F1:          {ann_cv_results['macro_f1_mean']:.4f} ± {ann_cv_results['macro_f1_std']:.4f}\")\n",
        "print(f\"Recall (Class 1):  {ann_cv_results['recall_class_1_mean']:.4f} ± {ann_cv_results['recall_class_1_std']:.4f}\")\n",
        "print(f\"ROC-AUC:           {ann_cv_results['roc_auc_mean']:.4f} ± {ann_cv_results['roc_auc_std']:.4f}\")\n",
        "print(f\"Avg Time (s):      {ann_cv_results['time_mean']:.2f} ± {ann_cv_results['time_std']:.2f}\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TEST SET EVALUATION (Threshold = 0.5)\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    y_test, ann_test_pred,\n",
        "    target_names=['Fully Paid (0)', 'Charged Off (1)'],\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, ann_test_pred)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=['Actual Fully Paid', 'Actual Charged Off'],\n",
        "    columns=['Pred Fully Paid', 'Pred Charged Off']\n",
        ")\n",
        "print(cm_df)\n",
        "print()\n"
      ],
      "metadata": {
        "id": "MkC-UmCeDIGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: VISUALIZATIONS\n",
        "\n",
        "print(\"Generating visualizations...\")\n",
        "\n",
        "# ROC Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "fpr, tpr, _ = roc_curve(y_test, ann_test_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f'ANN (AUC = {roc_auc:.4f})', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curve - Best Model', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('./results/roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ ROC curve saved\")\n",
        "\n",
        "# Precision-Recall Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "precision, recall, _ = precision_recall_curve(y_test, ann_test_proba)\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill Baseline')\n",
        "plt.plot(recall, precision, label='ANN', linewidth=2)\n",
        "plt.xlabel('Recall', fontsize=12)\n",
        "plt.ylabel('Precision', fontsize=12)\n",
        "plt.title('Precision-Recall Curve - Best Model', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('./results/precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Precision-Recall curve saved\")\n",
        "\n",
        "# Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Fully Paid', 'Charged Off'],\n",
        "            yticklabels=['Fully Paid', 'Charged Off'])\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Confusion Matrix - Best Model', fontsize=14, fontweight='bold')\n",
        "plt.savefig('./results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Confusion matrix saved\")\n",
        "\n",
        "# Threshold Analysis\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "macro_f1_scores = []\n",
        "\n",
        "for thresh in thresholds:\n",
        "    y_pred_thresh = (ann_test_proba > thresh).astype(int)\n",
        "    precision_scores.append(precision_score(y_test, y_pred_thresh, zero_division=0))\n",
        "    recall_scores.append(recall_score(y_test, y_pred_thresh, zero_division=0))\n",
        "    f1_scores.append(f1_score(y_test, y_pred_thresh, zero_division=0))\n",
        "    macro_f1_scores.append(f1_score(y_test, y_pred_thresh, average='macro', zero_division=0))\n",
        "\n",
        "optimal_macro_f1_idx = np.argmax(macro_f1_scores)\n",
        "optimal_recall_idx = np.argmax(recall_scores)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(thresholds, precision_scores, label='Precision', linewidth=2)\n",
        "plt.plot(thresholds, recall_scores, label='Recall', linewidth=2)\n",
        "plt.plot(thresholds, f1_scores, label='F1 Score', linewidth=2)\n",
        "plt.plot(thresholds, macro_f1_scores, label='Macro F1 Score', linewidth=2)\n",
        "plt.axvline(0.5, color='grey', linestyle='--', label='Default Threshold (0.5)')\n",
        "plt.axvline(thresholds[optimal_macro_f1_idx], color='green', linestyle=':',\n",
        "            label=f'Optimal Macro-F1 ({thresholds[optimal_macro_f1_idx]:.3f})')\n",
        "plt.xlabel('Threshold', fontsize=12)\n",
        "plt.ylabel('Score', fontsize=12)\n",
        "plt.title('Threshold Analysis - Best Model', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('./results/threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Threshold analysis saved\")\n"
      ],
      "metadata": {
        "id": "az7DDHlsDMaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: SAVE RESULTS\n",
        "\n",
        "# Save CV results\n",
        "cv_results_df = pd.DataFrame([{\n",
        "    'Metric': 'Accuracy',\n",
        "    'Mean': f\"{ann_cv_results['accuracy_mean']:.4f}\",\n",
        "    'Std': f\"{ann_cv_results['accuracy_std']:.4f}\"\n",
        "}, {\n",
        "    'Metric': 'Macro-F1',\n",
        "    'Mean': f\"{ann_cv_results['macro_f1_mean']:.4f}\",\n",
        "    'Std': f\"{ann_cv_results['macro_f1_std']:.4f}\"\n",
        "}, {\n",
        "    'Metric': 'Recall (Class 1)',\n",
        "    'Mean': f\"{ann_cv_results['recall_class_1_mean']:.4f}\",\n",
        "    'Std': f\"{ann_cv_results['recall_class_1_std']:.4f}\"\n",
        "}, {\n",
        "    'Metric': 'ROC-AUC',\n",
        "    'Mean': f\"{ann_cv_results['roc_auc_mean']:.4f}\",\n",
        "    'Std': f\"{ann_cv_results['roc_auc_std']:.4f}\"\n",
        "}])\n",
        "cv_results_df.to_csv('./results/cv_results.csv', index=False)\n",
        "\n",
        "# Save optimal thresholds\n",
        "threshold_results = pd.DataFrame([{\n",
        "    'Threshold Type': 'Default',\n",
        "    'Threshold': 0.500,\n",
        "    'Macro-F1': macro_f1_scores[50],\n",
        "    'Recall': recall_scores[50]\n",
        "}, {\n",
        "    'Threshold Type': 'Optimal Macro-F1',\n",
        "    'Threshold': thresholds[optimal_macro_f1_idx],\n",
        "    'Macro-F1': macro_f1_scores[optimal_macro_f1_idx],\n",
        "    'Recall': recall_scores[optimal_macro_f1_idx]\n",
        "}])\n",
        "threshold_results.to_csv('./results/optimal_thresholds.csv', index=False)\n",
        "\n",
        "print(\"\\n✓ Results saved to ./results/\")\n",
        "print(\"  - cv_results.csv\")\n",
        "print(\"  - optimal_thresholds.csv\")\n",
        "print(\"  - roc_curve.png\")\n",
        "print(\"  - precision_recall_curve.png\")\n",
        "print(\"  - confusion_matrix.png\")\n",
        "print(\"  - threshold_analysis.png\")\n"
      ],
      "metadata": {
        "id": "nx8rbwuIDRmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL SUMMARY\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL SUMMARY - BEST MODEL PERFORMANCE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model Architecture:    ANN with 2 Hidden Layers (14-7 neurons, tanh activation)\")\n",
        "print(f\"Balancing Strategy:    downsample_upsample\")\n",
        "print(f\"Feature Engineering:   Selected features + income-to-loan ratio\")\n",
        "print(f\"CV Macro-F1:           {ann_cv_results['macro_f1_mean']:.4f} ± {ann_cv_results['macro_f1_std']:.4f}\")\n",
        "print(f\"CV Recall (Class 1):   {ann_cv_results['recall_class_1_mean']:.4f} ± {ann_cv_results['recall_class_1_std']:.4f}\")\n",
        "print(f\"CV ROC-AUC:            {ann_cv_results['roc_auc_mean']:.4f} ± {ann_cv_results['roc_auc_std']:.4f}\")\n",
        "print(f\"\\nKey Achievement:\")\n",
        "print(f\"  Recall improved from ~3% (baseline) to {ann_cv_results['recall_class_1_mean']*100:.1f}%\")\n",
        "print(f\"  This means the model can now identify ~{ann_cv_results['recall_class_1_mean']*100:.0f}% of risky loans!\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n✓ ALL PROCESSING COMPLETE!\")"
      ],
      "metadata": {
        "id": "jYbN8i1pDVUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}