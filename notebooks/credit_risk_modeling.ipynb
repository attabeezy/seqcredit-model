{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Modeling: Static vs Sequential Approaches\n",
    "\n",
    "**Objective**: Compare Logistic Regression, XGBoost, and LSTM models for predicting\n",
    "probability of loan default using mobile money transaction data.\n",
    "\n",
    "**Target**: Binary classification -- default vs non-default (among borrowers only).\n",
    "\n",
    "**Models**:\n",
    "1. Logistic Regression (static, user-level features)\n",
    "2. XGBoost (static, user-level features)\n",
    "3. LSTM (sequential, per-transaction features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure src is importable from notebooks directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.models import (\n",
    "    CreditRiskDataLoader, LogisticRegressionModel,\n",
    "    XGBoostModel, LSTMModel, ModelEvaluator, set_random_seeds\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "set_random_seeds(42)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data for exploration\n",
    "df_features = pd.read_csv(os.path.join(project_root, 'data/user_features.csv'))\n",
    "df_summaries = pd.read_csv(os.path.join(project_root, 'data/user_summaries.csv'))\n",
    "\n",
    "print(f'User features: {df_features.shape}')\n",
    "print(f'User summaries: {df_summaries.shape}')\n",
    "print(f'\\nCredit risk label distribution (all users):')\n",
    "print(df_summaries['credit_risk_label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# All users\n",
    "labels_all = df_summaries['credit_risk_label'].value_counts().sort_index()\n",
    "label_names = {-1: 'No Loans', 0: 'Good', 1: 'Late', 2: 'Default'}\n",
    "ax1.bar([label_names[k] for k in labels_all.index], labels_all.values,\n",
    "        color=['#95a5a6', '#2ecc71', '#f39c12', '#e74c3c'])\n",
    "ax1.set_title('Credit Risk Labels (All Users)')\n",
    "ax1.set_ylabel('Count')\n",
    "for i, v in enumerate(labels_all.values):\n",
    "    ax1.text(i, v + 50, str(v), ha='center')\n",
    "\n",
    "# Borrowers only (binary target)\n",
    "borrowers = df_summaries[df_summaries['credit_risk_label'] != -1]\n",
    "binary = (borrowers['credit_risk_label'] == 2).astype(int)\n",
    "counts = binary.value_counts().sort_index()\n",
    "ax2.bar(['Non-Default', 'Default'], counts.values,\n",
    "        color=['#3498db', '#e74c3c'])\n",
    "ax2.set_title('Binary Target (Borrowers Only)')\n",
    "ax2.set_ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    ax2.text(i, v + 20, f'{v} ({v/len(borrowers)*100:.1f}%)', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nTotal borrowers: {len(borrowers)}')\n",
    "print(f'Default rate: {binary.mean():.3f} ({binary.sum()} defaults)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit archetype distribution among borrowers\n",
    "print('Credit archetypes (borrowers):')\n",
    "print(borrowers['credit_archetype'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader with paths relative to project root\n",
    "loader = CreditRiskDataLoader(\n",
    "    features_path=os.path.join(project_root, 'data/user_features.csv'),\n",
    "    summaries_path=os.path.join(project_root, 'data/user_summaries.csv'),\n",
    "    transactions_dir=os.path.join(project_root, 'data/user_transactions'),\n",
    ")\n",
    "\n",
    "# Prepare static data splits\n",
    "static_data = loader.prepare_static_splits()\n",
    "\n",
    "print(f\"Training samples: {len(static_data['y_train'])}\")\n",
    "print(f\"Test samples: {len(static_data['y_test'])}\")\n",
    "print(f\"Default rate (train): {static_data['y_train'].mean():.4f}\")\n",
    "print(f\"Default rate (test): {static_data['y_test'].mean():.4f}\")\n",
    "print(f\"Features: {len(static_data['feature_names'])}\")\n",
    "print(f\"Scale pos weight: {loader.get_scale_pos_weight():.2f}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, name in enumerate(static_data['feature_names']):\n",
    "    print(f\"  {i+1:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation with target (top features)\n",
    "X_train_df = static_data['X_train'].copy()\n",
    "X_train_df['default'] = static_data['y_train']\n",
    "correlations = X_train_df.corr()['default'].drop('default').abs().sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_corr = correlations.head(20)\n",
    "ax.barh(range(len(top_corr)), top_corr.values, color='#3498db')\n",
    "ax.set_yticks(range(len(top_corr)))\n",
    "ax.set_yticklabels(top_corr.index, fontsize=9)\n",
    "ax.set_xlabel('Absolute Correlation with Default')\n",
    "ax.set_title('Top 20 Features by Correlation with Default')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegressionModel(class_weight='balanced')\n",
    "lr_model.fit(static_data['X_train_scaled'], static_data['y_train'])\n",
    "\n",
    "# Cross-validation\n",
    "print('Logistic Regression - 5-Fold Cross-Validation:')\n",
    "lr_cv = lr_model.cross_validate(static_data['X_train_scaled'], static_data['y_train'])\n",
    "for metric, values in lr_cv.items():\n",
    "    print(f'  {metric}: {np.mean(values):.4f} +/- {np.std(values):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "lr_proba = lr_model.predict_proba(static_data['X_test_scaled'])\n",
    "\n",
    "print('Logistic Regression - Test Set Performance:')\n",
    "print(f'  AUC-ROC: {roc_auc_score(static_data[\"y_test\"], lr_proba):.4f}')\n",
    "print(f'  AUC-PR: {average_precision_score(static_data[\"y_test\"], lr_proba):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# Feature coefficients\n",
    "lr_coefs = lr_model.get_coefficients(static_data['feature_names'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_coefs = lr_coefs.head(15)\n",
    "colors = ['#e74c3c' if c > 0 else '#3498db' for c in top_coefs['coefficient']]\n",
    "ax.barh(range(len(top_coefs)), top_coefs['coefficient'], color=colors)\n",
    "ax.set_yticks(range(len(top_coefs)))\n",
    "ax.set_yticklabels(top_coefs['feature'], fontsize=9)\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_title('Logistic Regression - Top 15 Features by |Coefficient|')\n",
    "ax.invert_yaxis()\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Red = increases default probability, Blue = decreases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb_model = XGBoostModel(scale_pos_weight=loader.get_scale_pos_weight())\n",
    "xgb_model.fit(\n",
    "    static_data['X_train_scaled'], static_data['y_train'],\n",
    "    X_val=static_data['X_test_scaled'], y_val=static_data['y_test'],\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "print('XGBoost - 5-Fold Cross-Validation:')\n",
    "xgb_cv = xgb_model.cross_validate(static_data['X_train_scaled'], static_data['y_train'])\n",
    "for metric, values in xgb_cv.items():\n",
    "    print(f'  {metric}: {np.mean(values):.4f} +/- {np.std(values):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "xgb_proba = xgb_model.predict_proba(static_data['X_test_scaled'])\n",
    "\n",
    "print('XGBoost - Test Set Performance:')\n",
    "print(f'  AUC-ROC: {roc_auc_score(static_data[\"y_test\"], xgb_proba):.4f}')\n",
    "print(f'  AUC-PR: {average_precision_score(static_data[\"y_test\"], xgb_proba):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "xgb_importance = xgb_model.get_feature_importance(static_data['feature_names'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_imp = xgb_importance.head(15)\n",
    "ax.barh(range(len(top_imp)), top_imp['importance'], color='#2ecc71')\n",
    "ax.set_yticks(range(len(top_imp)))\n",
    "ax.set_yticklabels(top_imp['feature'], fontsize=9)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('XGBoost - Top 15 Feature Importances')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sequence data\n",
    "seq_data = loader.load_sequences(\n",
    "    max_seq_len=50,\n",
    "    cache_path=os.path.join(project_root, 'data/lstm_sequences.npz'),\n",
    ")\n",
    "\n",
    "print(f\"Train sequences shape: {seq_data['X_train_seq'].shape}\")\n",
    "print(f\"Test sequences shape: {seq_data['X_test_seq'].shape}\")\n",
    "print(f\"Train default rate: {seq_data['y_train'].mean():.4f}\")\n",
    "print(f\"Test default rate: {seq_data['y_test'].mean():.4f}\")\n",
    "print(f\"LSTM features ({len(seq_data['feature_names'])}):\")\n",
    "for i, name in enumerate(seq_data['feature_names']):\n",
    "    print(f\"  {i+1:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train LSTM\n",
    "input_shape = (seq_data['X_train_seq'].shape[1], seq_data['X_train_seq'].shape[2])\n",
    "class_weights = {0: 1.0, 1: loader.get_scale_pos_weight()}\n",
    "\n",
    "lstm_model = LSTMModel()\n",
    "lstm_model.build_model(input_shape)\n",
    "lstm_model.model.summary()\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    seq_data['X_train_seq'], seq_data['y_train'],\n",
    "    X_val=seq_data['X_test_seq'], y_val=seq_data['y_test'],\n",
    "    epochs=100, batch_size=32,\n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Train Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history['auc'], label='Train AUC')\n",
    "ax2.plot(history.history['val_auc'], label='Val AUC')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('AUC')\n",
    "ax2.set_title('Training AUC')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "lstm_proba = lstm_model.predict_proba(seq_data['X_test_seq'])\n",
    "\n",
    "print('LSTM - Test Set Performance:')\n",
    "print(f'  AUC-ROC: {roc_auc_score(seq_data[\"y_test\"], lstm_proba):.4f}')\n",
    "print(f'  AUC-PR: {average_precision_score(seq_data[\"y_test\"], lstm_proba):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Cross-validation (this will take a while)\n",
    "print('LSTM - 5-Fold Cross-Validation:')\n",
    "lstm_cv = lstm_model.cross_validate(\n",
    "    seq_data['X_train_seq'], seq_data['y_train'],\n",
    "    n_splits=5, epochs=100, batch_size=32,\n",
    "    class_weight=class_weights,\n",
    ")\n",
    "for metric, values in lstm_cv.items():\n",
    "    print(f'  {metric}: {np.mean(values):.4f} +/- {np.std(values):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator with the shared test set\n",
    "evaluator = ModelEvaluator(static_data['y_test'])\n",
    "evaluator.add_model('Logistic Regression', lr_proba)\n",
    "evaluator.add_model('XGBoost', xgb_proba)\n",
    "evaluator.add_model('LSTM', lstm_proba)\n",
    "\n",
    "# Comparison table\n",
    "comparison = evaluator.get_comparison_table()\n",
    "print('\\nModel Comparison (Test Set):')\n",
    "print(comparison.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation comparison\n",
    "cv_results = {}\n",
    "for name, cv in [('Logistic Regression', lr_cv), ('XGBoost', xgb_cv), ('LSTM', lstm_cv)]:\n",
    "    cv_results[name] = {\n",
    "        metric: f\"{np.mean(values):.4f} +/- {np.std(values):.4f}\"\n",
    "        for metric, values in cv.items()\n",
    "    }\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "print('\\nCross-Validation Results (5-Fold):')\n",
    "print(cv_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and PR curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "evaluator.plot_roc_curves(ax=ax1)\n",
    "evaluator.plot_pr_curves(ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "evaluator.plot_confusion_matrices(figsize=(16, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance comparison (LR vs XGBoost)\n",
    "evaluator.plot_feature_importance_comparison(\n",
    "    lr_coefs, xgb_importance, top_n=15\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold analysis for each model\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for ax, name in zip(axes, ['Logistic Regression', 'XGBoost', 'LSTM']):\n",
    "    evaluator.plot_threshold_analysis(name, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "evaluator.print_classification_reports()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**Static vs Sequential Performance:**\n",
    "- Compare AUC-ROC and AUC-PR scores across models to determine whether\n",
    "  the LSTM's ability to model temporal transaction patterns provides\n",
    "  meaningful lift over user-level aggregates used by LR and XGBoost.\n",
    "\n",
    "**Feature Importance Insights:**\n",
    "- Loan-specific features (repayment_to_loan_ratio, has_any_repayment, etc.)\n",
    "  are expected to be strong predictors given the target is loan default.\n",
    "- Balance dynamics and transaction patterns may provide additional signal.\n",
    "\n",
    "**Class Imbalance:**\n",
    "- With ~9% default rate, AUC-PR (Average Precision) is more informative\n",
    "  than AUC-ROC for assessing model quality on the minority class.\n",
    "\n",
    "**Practical Considerations:**\n",
    "- Logistic Regression offers full interpretability via coefficients.\n",
    "- XGBoost typically offers the best accuracy-to-complexity tradeoff.\n",
    "- LSTM captures sequential patterns but requires more data and compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison table\n",
    "comparison.to_csv(os.path.join(project_root, 'data/model_comparison.csv'))\n",
    "print('Comparison table saved to data/model_comparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
